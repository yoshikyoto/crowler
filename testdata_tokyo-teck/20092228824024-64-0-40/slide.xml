<presentation language="ja">
<slide page="1">
<body>
<p>
知的画像処理（９） 1
最適化のための基礎
</p>
</body>
</slide>
<slide page="2">
<body>
<p>
知的画像処理（９） 2
最適化に基づく画像処理の必要性
理由
ビジョン問題では，観測時の雑音やオクルージョンに
起因する不確かさが存在し，完全に正確な解を得るこ
とは困難．
多くのビジョン問題が最適化問題として
定式化される
</p>
</body>
</slide>
<slide page="3">
<body>
<p>
知的画像処理（９） 3
画像処理の最適化と統計的手法
画像処理における最適化とは、ある基準に基づいて
最も良く目的を達成することを目指すもの。
統計的画像処理とは、画像の表現に統計モデルを導入し、
そのモデルパラメータを推定することで、結果として目
的とする画像を得る手法。
統計的画像処理手法では、MRFやGRFによるモデル化
がしばしば利用される。
</p>
</body>
</slide>
<slide page="4">
<body>
<p>
知的画像処理（９） 4
最適化手法における三要素
1．問題の表現
どんな特徴で解を形式化するか
２．目的関数
最適化をどのように基準化するか
３．最適化アルゴリズム
どのようにして最適値を探索するか
</p>
</body>
</slide>
<slide page="5">
<body>
<p>
知的画像処理（９） 5
目的関数の形式化
最適化アルゴリズム
表現のスキーム
•目的関数としては，エネルギー関数や（対数）尤度関数，
事後確率など．
•最適化手法には様々な方法があって，それぞれ特徴あり．
•目的関数とその最適化法とは密接に関係．
</p>
</body>
</slide>
<slide page="6">
<body>
<p>
知的画像処理（９） 6
データ分布のみがあり、推定量の事前情報がない
最大尤度 (maximum likelihood)推定
逆の場合
最大エントロピー (maximum entropy)推定
推定量の事前情報とデータ分布がともに既知
Bayes基準
最大事後確率(maximum a posterior;MAP)推定
最大事後確率平均(maximum a posterior mean;)推定
最適化基準
</p>
</body>
</slide>
<slide page="7">
<body>
<p>
知的画像処理（９） 7
エネルギー関数の役割
１．解の大局性を定量的に表現．
２．最小解に対する探索の指針を提供．
エネルギー関数
エネルギー関数の定式化
⎩⎨
⎧
表現ノンパラメトリックな
パラメトリックな表現基本的方法
),|(minarg* θdfEf
f
= は観測データd
に依存とパラメータ関数形式最小解 θEf :*
</p>
</body>
</slide>
<slide page="8">
<body>
<p>
知的画像処理（９） 8
0)(
1)(
:)(;
)(
)()(
},, 21
=
=
=
=∩
⊆
ΩΩΩ
φ
φ
P
P
AAn
n
AnAPA
BABA
AA
n
　　
　　
の要素の数事象の確率・事象
反である。・根元事象は互いに排
いう。は互いに排反であると　と書き、２つの事象
とき、が同時には起こらないと・２つの事象
：　象・試行の結果起こる事
＝｛：　・根元事象全体の集合
１つ：　根元事象・基本的な事象の１つ
事がら：　事象・試行によって起こる
：　試行　・ある操作を行うこと
Ω
Ω
Ω
Ω L
事象・集合・確率
</p>
</body>
</slide>
<slide page="9">
<body>
<p>
知的画像処理（９） 9
任意の事象　　
系列　排反、網羅的な事象
:
:),,1(
E
nnHn L=
),()()|()()|( EHPHPHEPEPEHP nnnn ==
)()|(
)()|(
)()|(
)(
)|()()|(
0)(
nn
m
mm
nn
nn
n
HPHEP
HPHEP
HPHEP
EP
HEPHPEHP
EP
∝
=
=
≠
∑
が与えられると、従って、
Bayesの定理
</p>
</body>
</slide>
<slide page="10">
<body>
<p>
知的画像処理（９）10
確率変数と確率分布
『例』サイコロ
サイコロを振る操作：試行
いずれかの目が出る：根元事象
根元事象に割り当てられた数値：実現値{1,2,3,4,5,6}
試行にともなって出る目を表す変数 X：確率変数
確率変数Xの実現値が離散的：離散的確率変数
連続的：連続的確率変数
</p>
</body>
</slide>
<slide page="11">
<body>
<p>
知的画像処理（９）11
という。
ているに確率分布が与えられと表し、確率変数
：確率関数
とき
既知の現値の得られる確率が離散的確率変数の各実
X
PP
PxXPxXP
i
n
i
i
iiiii
,1
,)(}))(;({
1
∑
=
=
====ΩΩ
離散的確率分布
</p>
</body>
</slide>
<slide page="12">
<body>
<p>
知的画像処理（９）12
連続的確率分布
確率変数Xの実現値xが連続な場合、実現値の微小区間を
考え、Xの実現値がこの間に入る確率を次のように表す。
∫ ∞+∞− =
=+≤≤
1)()(
)()(
dxxpxp
xxpxxXxP
、を確率密度関数といい
δδ
（累積）分布関数 F(x)
∫
∑
∞−
≤
=
=
x
xx
i
dxxpxF
PxF
i
連続的確率分布
離散的確率分布
)()(
)(
</p>
</body>
</slide>
<slide page="13">
<body>
<p>
知的画像処理（９）13
正規分布
となる。で、正規分布変数変換と
数の分布は、適当なの和で表される確率変
個の離散的確率変数いに独立な同一の分布に従う、互
)1,0(
,,, 21
NN
XXX
N
N
∞→
L
と表す。～であり、
従うとき、
の正規分布に分散が平均ある連続的確率変数
),(
2
1)()(
,
2
2/)(
2
2
22
σμ
πσ
σμ
σμ
Nx
expxXP
X
x−−===
中心極限定理
</p>
</body>
</slide>
<slide page="14">
<body>
<p>
知的画像処理（９）14
標本抽出と母集団
• 全体から選び出されたもの：標本
• 標本の背後に存在する全体：母集団
• 母集団から標本を抽出する操作：標本抽出
値を持つことと同等。
の実現が，それぞれ確率変数
個のな造をもつ，互いに独立母集団と同じ確率的構
プリングという値の標本をサン大きな母集団から
nn
n
xxxXXX
n
xxx
,,,,,,
:,,,
2121
21
LL
L
互いに独立で同一な確率分布に従うn個の確率変数:
i.i.d.(independent identically distributed)な確率変数
</p>
</body>
</slide>
<slide page="15">
<body>
<p>
知的画像処理（９）15
乱数発生法
• 一様乱数:: メルセンヌ・ツイスタ法
M.Matsumoto and T.Nishimura, Mersenne twister: A 623 dimensionally  
equidistributed uniform pseudorandom number generator, ACM Trans. on  Modeling 
and Computer Simulation,1998
• 正規分布乱数:: ボックス・ミューラ法
で発生可能．に従う乱数は、変換
を以下の式で発生．正規乱数
に従う２個のから，正規分布２個の一様乱数
ii zN
rrz
rrz
zz
Nrr
22
2
2/1
12
2
2/1
11
21
21
),(
2sin)log2(
2cos)log2(
,
)1,0(,
σμςσμ
π
π
+=
−=
−=
• その他の分布の乱数::  
棄却サンプリング、SIR、MCMC等の方法で発生
</p>
</body>
</slide>
<slide page="16">
<body>
<p>
知的画像処理（９）16
非線形最適化問題
非線形最適化問題
⎡ ⎡⎢ ⎢⎣⎢⎢
⎡⎢ ⎢⎣⎣
単峰性関数最適化制約なし最適化
多峰性関数最適化
等式制約下での最適化
制約つき最適化
不等式制約下での最適化
問題の分類
手法の分類
Newton法
GA
⎡
⎡⎢⎢⎢⎣⎢⎢
⎡⎢ ⎢⎣
最急降下法
勾配法
共役勾配法非線形最適化手法
シンプレックス法直接探索法 実数値
⎣
</p>
</body>
</slide>
<slide page="17">
<body>
<p>
知的画像処理（９）17
制約なし非線形最適化問題
nRxforxfxf ∈∀≤ )()( *
が成り立つとき、 x*を〔問題１〕の大域的最適解
（global optimal solution）という。
が成り立つとき、 x*を〔問題１〕の局所的最適解
（local optimal solution）という。
ここで、 fは Rn上で定義される非線形関数．
{ }δδ ≤−=∈∀≤ xxxxNxforxfxf *** ),()()(
)(:min x
x
f
nR∈
〔問題1〕
</p>
</body>
</slide>
<slide page="18">
<body>
<p>
知的画像処理（９）18
)point stationary(:)( の停留点を満たす点 ff ∗=∇ x0x
[ ] ．，の局所的最適解ならば問題１が点 0xx =∇ ∗∗ )(f
[ ]
．要条件は，最適解であるための必
の大域的問題１が点が凸関数であるとき，
0x
x
=∇ ∗
∗
)(f
f
最適性条件
．階連続微分可能とするは（仮定） 2: RRf n →
</p>
</body>
</slide>
<slide page="19">
<body>
<p>
知的画像処理（９）19
O x
f(x)
A CB
A, B, C, D：停留点
A, C：局所的最適解
C：大域的最適解
D
(stationary point)
(local optimal solution)
(global optimal solution)
</p>
</body>
</slide>
<slide page="20">
<body>
<p>
知的画像処理（９）20
降下方向
の降下方向と言う．における点
を、なる
f
f T
x
ddx 0)( <∇
と言う．を最急降下方向 (steepest descent direction)
)(
)(
0)()()(
)(
),(
xd
xBd
xBxdx
xBd
B
f
B
f
fff
f
nn
TT
−∇=
∇−=
<∇−∇=∇
∇−=
が単位行列のとき、特に、
す．は降下方向条件を満た従って、
となる．
とすれば、
に対しての正定値対称行列
</p>
</body>
</slide>
<slide page="21">
<body>
<p>
知的画像処理（９）21
降下方向の例
∇f(x(0))
d(1) =－B(1)∇f(x(0))
－∇f(x(0))d(2) =－B(2)∇f(x(0))
x(0)
</p>
</body>
</slide>
<slide page="22">
<body>
<p>
知的画像処理（９）22
勾配法の概要
B(k)が単位行列のとき，最急降下法（steepest descent method）
へ．としてそうでなければ
であれば探索終了．
を更新．を解き、
直線探索を決定．ステップ幅
　
を決定．で降下方向適当な正定値対称行列
を選択．初期探索点
Step21
0)(:Step4
)(minarg
:Step3
)(
:Step2
0：Step1
)1(
)()()()1(
)(
)()()(
)(
)()(
)()(
)0(
+=
=∇
+=
+=
⇒
∇−=
=
+
+
kk
f
a
x
afa
a
f
k
k
kkkk
k
kk
a
k
k
kk
kk
x
dxx
dx
xBd
dB
x
</p>
</body>
</slide>
<slide page="23">
<body>
<p>
知的画像処理（９）23
)( )()( kk f xd −∇=
)0(x
)0(d
)1(x )1(d
)2(d
)3(d
)2(x
)3(x
)4(x
最急降下法の収束性
</p>
</body>
</slide>
<slide page="24">
<body>
<p>
知的画像処理（９）24
とし，を，正定値行列 1)(2)()( ))((Step2 −∇= kkk f xBB
とする．)()(( )(1)(2)( kkk ff xxd ∇⋅∇−= −
として，をステップ幅 1,Step3 )( =kαα
)()()()1( kkkk dxx α+=+
へとしてそうでなければ， Step21+= kk
:
)(minargStep3 )()()(
と直線探索
で，ステップ幅を kkk f dx αα α +=直線探索付きニュートン法
ニュートン法の概要
であれば探索終了．0)(Step4 )1( =∇ +kxf
0Step1 )0( =kx を選択．初期探索点
</p>
</body>
</slide>
<slide page="25">
<body>
<p>
知的画像処理（９）25
ニュートン法と最急降下法の混合．
ヘッセ行列の計算が重い．
{ }
10
)()()1( )(
1)(2)(
≤≤
∇+∇−−= −
α
αα
ここで，
kkk ff xIxd
法）．修正ニュートン法（
行列を作成．　
を加え、正定値化したの対角要素に適当な値
存在が保証されない．
の効率的．しかし，進めばニュートン法は
探索が数で近似可能であり、最適解近傍は凸２次関
MarquartLevenberg
)(
))((
2
12
−
∇
∇ −
xf
xf
修正ニュートン法
</p>
</body>
</slide>
<slide page="26">
<body>
<p>
知的画像処理（９）26
)())(( )(1)(2)( kkk ff xxd ∇∇−= −
ニュートン法最急降下法
修正ニュートン法
)( )()( kk f xd −∇=
{ } )()()1( )(1)(2)( kkk ff xIxd ∇+∇−−= −αα
</p>
</body>
</slide>
<slide page="27">
<body>
<p>
知的画像処理（９）27
へ戻る．
　とする．
を解き，
ステップサイズの決定
ならば終了．
を選択．初期探索点
Step2
1,
)(minarg
Step3
1,
)()(
)()()(
)( Step2
0),(
Step1
)()()()1(
)()(
0
)(
)1(
)1()1(
)()(
)()(
)(
)0()0(
)0(
+=+=
+=
≥∇∇
∇∇+−∇=
=∇
=−∇=
+
>
−
−−
kk
f
k
ff
fff
f
kf
kkkk
kkk
k
kTk
kTk
kk
k
dxx
dx
d
xx
xxxd
0x
xd
x
α
αα α
Fletcher-Reeves法（共役勾配法）
</p>
</body>
</slide>
<slide page="28">
<body>
<p>
知的画像処理（９）28
等式制約の下での最適化
ラグランジュ関数
ラグランジュ乗数
のラグランジュ関数は〔問題４：等式制約〕
:),,1(
),()(),(
1
mi
gfL
i
m
i
ii
L=
+= ∑
=
λ
λ xxλx
),,1(0)(subj.to)(min migf iRn
L==
∈
xx
x
〔問題４：等式制約〕
</p>
</body>
</slide>
<slide page="29">
<body>
<p>
知的画像処理（９）29
0λx0λx
λx
λλxxλλλxxx =∇=∇ ∗∗∗∗ ====
∗∗
,, ),(,),( LL
要条件は，最適解を持つための必
で局所的とジュ関数が〔問題４〕のラグラン
0xλx
0xxλx
λλxxλ
λλxxx
===∇
=∇+∇=∇
∗∗
∗∗
==
===
∑
T
i
m
i
ii
migL
gfL
),,1),((),(
)()(),(
*
,
1
***
,
L
λ
〔問題4〕のKKT条件と等しい．
ラグランジュの未定乗数法
</p>
</body>
</slide>
<slide page="30">
<body>
<p>
知的画像処理（９）30
.042426,
4
2
6
2
2
2
)42426()(),,,(
321
3
2
1
321
2
3
2
2
2
1321
=−++=∇=
⎟⎟
⎟
⎠
⎞
⎜⎜
⎜
⎝
⎛
+
⎟⎟
⎟
⎠
⎞
⎜⎜
⎜
⎝
⎛
=∇
−+++++=
xxxL
x
x
x
L
xxxxxxxxxL
λλ
λλ
0x
最適性条件より
ラグランジュ関数は，
.2
63)3,2
3,2
9(2
3 ，最適値は．従って，最適解は
すれば，で表し，制約式に代入が得られる．各変数を
−=∗λ
λ
42426subj.tomin 321
2
3
2
2
2
1,, 321
=++++= xxxxxxf
xxx
法（最小化問題）の例ラグランジュ未定乗数
</p>
</body>
</slide>
<slide page="31">
<body>
<p>
知的画像処理（９）31
EMアルゴリズム
データの総称．
）も含めた（隠れ変数や潜在変数本来観測できない変数
ではなく，損値を含むデータだけ不完全データとは，欠
Rubin)Laird, Dempster, (1977,
EM
。求める理論的な枠組み
定値を完全データから最尤推アルゴリズムとは，不
化する．期待値を逐次的に最大
件付代わりに，次に示す条法は，対数尤度関数の
数はとすると，対数尤度関
，モデルパラメータ，隠れ変数集合観測データ集合
EM
)|,(log)|(log)( ∑
Ζ
== θZDθDθD,
θZD
ppL
</p>
</body>
</slide>
<slide page="32">
<body>
<p>
知的画像処理（９）32
．逐次的に最大化を行うに関して以下のようにθ
∑=
=
Z
θZD,θDZ
θDθZDθθ
)|(log),|(
},|)|,({log)|(
)(
)()(
pP
pEQ
t
t
Z
t
とする．とし，
を計算．
理を繰り返す．収束するまで以下の処
とする．を設定し，初期値
1)|(maxarg:step-M    
)|( :step-E     
 Step2.
0 Step1.
)(1)(t
)(
(0)
+←=
←
+ ttQ
Q
t
t
t
θθθ
θθ
θ
θ
EMアルゴリズム
尤法）対数尤度の最大化（最関数の最大化Q
</p>
</body>
</slide>
<slide page="33">
<body>
<p>
知的画像処理（９）33
正規混合分布の最尤推定
)}()(
2
1exp{||)2(),;(
,),;(
1,),;()(
12/12/
11
μxΣμxΣΣμx
ΣμΣμ
Σμxθ|x
−−−=
∈∈⋅
==
−−−
×
==
∑∑
Td
ddd
m
i
i
m
i
iii
N
RRN
Np
m
π
αα
持つ多次元正規分布．
を共分散行列は，平均ベクトル
　　ただし，
らなる分布個の正規分布の混合か正規混合分布：
を推定する問題．未知パラメータ
から，最尤法によって観測データ集合
m
iiii
N
jj
1
1
},,{
}{
=
=
=
=
Σμθ
xD
α
</p>
</body>
</slide>
<slide page="34">
<body>
<p>
知的画像処理（９）34
画像の統計モデル
),;()|(
1
ii
m
i
iNp Σμxθx ∑
=
= α
デル多変量混合正規分布モ
定）として画像が存在（仮
布個の正規分布の混合分m
</p>
</body>
</slide>
<slide page="35">
<body>
<p>
知的画像処理（９）35
．のいずれかの値をとる標で，発生したのかを示す指
がどの混合成分からは，観測データ隠れ変数
},,1{
}{ 1
m
zz i
N
jji
L
xZ ==∈
)},;(log{
),;(
),;(
)|,(log),|()(
),;()|,(
)|,(
)|,(
)|(
)|,(),|(
1 1
1
)()()(
)()()(
1 1
)()(
1
)(
)(
)(
)(
)(
iini
m
i
N
n m
j
t
j
t
jn
t
j
t
i
t
in
t
i
nn
m
i
N
n
t
nn
t
iininn
m
i
t
nn
t
nn
t
n
t
nnt
nn
N
N
N
izpizPQ
Nizp
izp
izp
p
izpizP
Σμx
Σμx
Σμx
θxθxθ|θ
Σμxθx
θx
θx
θx
θx
θx
αα
α
α
∑ ∑ ∑
∑∑
∑
= =
=
= =
=
=
===
==
=
=====
より，
EMアルゴリズムによる推定
</p>
</body>
</slide>
<slide page="36">
<body>
<p>
知的画像処理（９）36
の最大化．つき：等式拘束条件 )|()1(step-M )(
1
t
m
i
i Q θθα∑
=
=
数法による解法ラグランジェの未定乗
を求める．を満たす
関数）として（ラグランジェ
),(
|),(,|),(
)1()|(),(
**
1
)(
**
λθ
λλ
αλλ
λ 0θ0θ
θθθ
,θθ,θθθ ** =∇=∇
−+=
====
=
∑
λλλλ
m
i
i
t
GG
QG
が条件となる．
と，これを各成分毎に表す
0),(,0)|(,0)|( 1
)()(
=∂
∂=Σ∂
∂=∂
∂
−
ii
t
i
t GQQ
α
λθθθ
μ
θθ
</p>
</body>
</slide>
<slide page="37">
<body>
<p>
知的画像処理（９）37
．，上記反復処理を実行に適当な初期値を与え
ただし，
られる。と，以下の更新式が得以上のことを踏まえる
)0()0()0(
1
)()(
)1()1()1(
)(
)1(
)1()(
1
)(
)1(
1
)(
)(
)1(
,,
),|(
,))((
,),|(1
,),|(1
iii
N
n
t
nn
t
i
Tt
in
t
in
t
ni
t
it
i
t
ni
t
nn
N
n
t
i
t
i
N
n
n
t
nnt
i
t
i
izPN
N
N
izP
N
izP
N
Σ
==
−−=
=
==
==
∑
∑
∑
=
+++
+
+
=
+
=
+
μα
α
θx
μxμxV
VθxΣ
xθxμ
</p>
</body>
</slide>
</presentation>
